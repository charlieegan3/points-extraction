\chapter{Background \& Related Work\label{chap:background-related}}
  \section{Background}
    This project is built on existing technologies and research. This section gives an overview of the key foundations.

    \subsection{Automatic Summarization}
      ``A summary can be loosely defined as a text that is produced from one or more texts, that conveys important information in the original text(s), and that is no longer than half of the original text(s) and usually significantly less than that.'' \cite{radev2002introduction}

      Approaches to summarization could be grouped loosely into two groups, extractive and abstractive. Extractive summaries are constructed using content found in the source text. Abstractive summaries generate the summary content by performing some form of analysis on the source text. One might also group summarization tasks based on the nature of the source text. Approaches tend to summarize either single or multiple documents.

      This project is more closely related to the summarization of multiple documents, however, it applies both elements of extraction and abstraction.

      \subsubsection{Multi-document Summarization}
        Summarizing text made up of documents from different authors poses an interesting challenge. Using multiple documents introduces repetition and contradictions - this makes selection tasks such as extraction and compression more complex.

        Earlier work on multi-document summarization suggested the task was going to require an abstractive approach \cite{McKeown1999TMS315149315355}. The justification being that extraction techniques used for single document summaries, not being able to connect information between documents, would lead to incoherent and repetitive summaries. An alternative approach clustered paragraphs on the same topic from multiple documents and then use natural language generation techniques to combine phrases from paragraphs into a coherent summary \cite{McKeown1999TMS315149315355}. A similar approach creates clusters by parsing sentences and using predicate-argument structures to link phrases \cite{barzilay1999information} (comment about being similar to our points extraction and grouping?). Interestingly, while both rely methods rely on natural language generation, neither use a semantic representation.

        More recently, MEAD, a centroid-based, multi-document summarization tool has been able to produce good summaries without abstraction and generation \cite{radev2000centroid}. Compared to previous abstractive systems such as SUMMONS that relied on templates \cite{mckeown1995generating}, MEAD was more generally applicable.

        Most work on the summarization of multi-document sources has focused on news articles. While there are parallels between this and the summarization of online discussion, fundamentally they are different tasks. More closely related to this project is opinion mining.

        Opinion mining or sentiment analysis is an approach often applied to user reviews, documents discussing a product or service. Early work in the area focused on the problem as a classification task, categorizing documents based on their sentiment bearing terms \cite{turney2002thumbs}. More recently there as been a greater focus on aspect-based approaches that attempt isolate sentiment terminology to specific topics such as product features \cite{hu2004mining}.

      \subsubsection{Sentence Compression \& Content Unit Size}
        While sentences are often the default `content unit' used in extractive summarization, often smaller units are more desirable. Sentences found in real documents and discussions can make a number of statements each of which can be useful when creating a summary. Sentences may also include surplus information. In this case sentences can be compressed statistically, in a similar way to documents are in extractive summarization.

        Both noisy channel and decision based models have used on parsed sentences for the task of sentence compression \cite{knight2000statistics}. Our approach for compression where points are extracted around a verb, does not seem to have been previously documented.

        (comment that the largest coherent unit is a sentence in an extractive summary, even that might not be right (bad grammar, co-referring expressions). Reference: Ultra-Summarization: A Statistical Approach to Generating
        Highly Condensed Non-Extractive Summaries)

      \subsubsection{Evaluation of Summaries}
        The evaluation of automatically generated summaries is an ongoing discussion. A common approach is to make a comparison against a model summary, typically written by a human. Various metrics such as ROUGE \cite{lin2004rouge} are used to make the comparison between summaries statistically. These are however limited by the assumption that there is a single best model for a summary. Alternative methods have been proposed. The Pyramid Method is one such example, it models content units across the collection of summaries being evaluated to give each content unit a weight based on how commonly it occurs \cite{nenkova2004evaluating}. These weights are used to allocate scores to summaries without an ordering bias.

        Automated methods are used primarily at the Document Understanding Conference when many summaries must be evaluated for a given task. Ideally however summaries could be manually evaluated. This would allow extrinsic attributes such as the utility of a summary for a particular task to also be accounted for. (reference to SUMMAC?, automated http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.489)

    \subsection{Argumentation Mining}
      Argumentation Mining is a task that involves the identification components of arguments within text such as premises and the conclusion. The task also often involves fitting these components into a template or known pattern to enable some form of reasoning. \cite{palau2009argumentation}

      A relatively new research area - combining ideas from natural language processing, information extraction and argumentation theory - argumentation mining is based largely on discourse  theory. While argumentation mining can be applied to structured text (source?), ultimately mining of free text is the goal. This means that argumentation tools often need to model concepts from linguistic research such as rhetoric structure theory \cite{mann1988rhetorical} and local coherence centering \cite{weinstein21centering}.

      \subsubsection{Identifying Argumentative Structures in Text}
        When identifying argumentative structures in text the first step is often to classify phrases that are part of an argument being made. One of option is to define rules for argumentative sentences or clauses. This can also be approached as a classification task, statistical methods such naive-bayes have also been used \cite{palau2009argumentation}. The result of this stage is a collection of unrelated clauses potentially spanning many arguments present in the source text.

        The next stage in the analysis is to group identified units together into separate arguments. While sometimes the document's structure (chapters and sections) can be used to inform the grouping task this is hard to make generally applicable. Documents are rarely consistently formatted and arguments will often span many sections. Other options include grouping based on the similarity of the unit contents - presence of certain words etc. \cite{palau2009argumentation}

        Once identified units have been grouped into different arguments it becomes possible to start looking into the argument's structure. Different units need to be classified as either premises or conclusions - this can again be approached as a classification task \cite{palau2009argumentation}. Once such as structure for the units has been established it's possible to do analysis this connected structure such as identifying supporting claims for conclusions.

        A further task is relating arguments within the document to one another, this is a far more challenging task. Fitting the argument structure to allowed patterns defined by a context-free grammar is one proposed approach \cite{palau2009argumentation}.

    \subsection{Dependencies}
      The approach implemented as part of this project relies on the products of research in the following areas.
      \subsubsection{Topic Modeling}
        Topic modeling covers a set statistical modeling techniques used to identify and group `topics' in text. Fundamentally, this involves looking for words that are relatively more common on one document vs a more general corpus. Documents often contain multiple topic words that need to be grouped into more conceptual topics. One approach to this is is Latent Dirichlet Allocation (LDA), this implements a "three-level hierarchical Bayesian model" \cite{blei2003latent} and is the approach used for topic modeling in this project.
      \subsubsection{Dependency Parsers}
        Parsing text for dependencies involves building upon a phrasal parse to extract relations between tokens in text. Dependencies are identified using rules applied to phrase structure trees. Various dependency parsers exist, this project makes use of the dependency parser included as part of the Stanford CoreNLP framework \cite{de2006generating} which is based on their probabilistic context-free grammar phrasal parser \cite{klein2003accurate}. The rules used in the Stanford dependency parser based on ``Universal Stanford Dependencies" \cite{de2014universal}.
      \subsubsection{Querying Dependency Parses}
        To make use of the dependency parse a means of querying the graph is required. \textit{Semgrex} is one such approach, this defines a regular expression style syntax for expressing queries on nodes and relations in a dependency graphs \cite{Chambers2007}. More generally however, the task about querying nodes and edges in a directional graph. For this project we opted to use \textit{Cypher}\footnote{http://neo4j.com/docs/stable/cypher-introduction.html}, the graph query language implemented by the \textit{Neo4j}\footnote{http://neo4j.com/} graph database. This was chosen for the querying of dependency parses because it allowed many separate graphs to be queried in parallel for the same pattern using a more familiar declarative syntax.

  \section{Related Work}
    Overview of related work on the topic that's also related to my project
    \subsection{Opinion Mining and Summarization of Discussions}
    \subsection{Multi-document Summarization}
    \subsection{Informal Argumentation}
    \subsection{Stance Classification}
  \section{Motivation}
    Round up why our project is different and interesting
