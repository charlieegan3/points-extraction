\chapter{Background \& Related Work\label{chap:background-related}}
  \section{Background}
    This project is built on existing technologies and research. This section gives an overview of the key foundations.

    \subsection{Automatic Summarization}
      ``A summary can be loosely defined as a text that is produced from one or more texts, that conveys important information in the original text(s), and that is no longer than half of the original text(s) and usually significantly less than that.'' \cite{radev2002introduction}

      Approaches to summarization could be grouped loosely into two groups, extractive and abstractive. Extractive summaries are constructed using content found in the source text. Abstractive summaries generate the summary content by performing some form of analysis on the source text. One might also group summarization tasks based on the nature of the source text. Approaches tend to summarize either single or multiple documents.

      This project is more closely related to the summarization of multiple documents, however, it applies both elements of extraction and abstraction.

      \subsubsection{Multi-document Summarization}
        Summarizing text made up of documents from different authors poses an interesting challenge. Using multiple documents introduces repetition and contradictions - this makes selection tasks such as extraction and compression more complex.

        Earlier work on multi-document summarization suggested the task was going to require an abstractive approach \cite{McKeown1999TMS315149315355}. The justification being that extraction techniques used for single document summaries, not being able to connect information between documents, would lead to incoherent and repetitive summaries. An alternative approach clustered paragraphs on the same topic from multiple documents and then use natural language generation techniques to combine phrases from paragraphs into a coherent summary \cite{McKeown1999TMS315149315355}. A similar approach creates clusters by parsing sentences and using predicate-argument structures to link phrases \cite{barzilay1999information} (comment about being similar to our points extraction and grouping?). Interestingly, while both rely methods rely on natural language generation, neither use a semantic representation.

        More recently, MEAD, a centroid-based, multi-document summarization tool has been able to produce good summaries without abstraction and generation \cite{radev2000centroid}. Compared to previous abstractive systems such as SUMMONS that relied on templates \cite{mckeown1995generating}, MEAD was more generally applicable.

        Most work on the summarization of multi-document sources has focused on news articles. While there are parallels between this and the summarization of online discussion, fundamentally they are different tasks. More closely related to this project is opinion mining.

        Opinion mining or sentiment analysis is an approach often applied to user reviews, documents discussing a product or service. Early work in the area focused on the problem as a classification task, categorizing documents based on their sentiment bearing terms \cite{turney2002thumbs}. More recently there as been a greater focus on aspect-based approaches that attempt isolate sentiment terminology to specific topics such as product features \cite{hu2004mining}.

      \subsubsection{Sentence Compression \& Content Unit Size}
        While sentences are often the default `content unit' used in extractive summarization, often smaller units are more desirable. Sentences found in real documents and discussions can make a number of statements each of which can be useful when creating a summary. Sentences may also include surplus information. In this case sentences can be compressed statistically, in a similar way to documents are in extractive summarization.

        Both noisy channel and decision based models have used on parsed sentences for the task of sentence compression \cite{knight2000statistics}. Our approach for compression where points are extracted around a verb, does not seem to have been previously documented.

        (comment that the largest coherent unit is a sentence in an extractive summary, even that might not be right (bad grammar, co-referring expressions). Reference: Ultra-Summarization: A Statistical Approach to Generating
        Highly Condensed Non-Extractive Summaries)

      \subsubsection{Evaluation of Summaries}
        The evaluation of automatically generated summaries is an ongoing discussion. A common approach is to make a comparison against a model summary, typically written by a human. Various metrics such as ROUGE \cite{lin2004rouge} are used to make the comparison between summaries statistically. These are however limited by the assumption that there is a single best model for a summary. Alternative methods have been proposed. The Pyramid Method is one such example, it models content units across the collection of summaries being evaluated to give each content unit a weight based on how commonly it occurs \cite{nenkova2004evaluating}. These weights are used to allocate scores to summaries without an ordering bias.

        Automated methods are used primarily at the Document Understanding Conference when many summaries must be evaluated for a given task. Ideally however summaries could be manually evaluated. This would allow extrinsic attributes such as the utility of a summary for a particular task to also be accounted for. (reference to SUMMAC?, automated http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.489)

    \subsection{Argument Mining}
      Argumentation Mining is a task that involves identifying components of arguments within text such as premises and the conclusion. Part of the task often involves fitting these into a template or known pattern to enable some level of reasoning.
      \subsubsection{Identifying Argumentative Structures in Text}
      \subsubsection{Argument Relationships}
    \subsection{Dependency: Topic Modeling}
    \subsection{Dependency: Probabilistic Parsers}
    \subsection{Dependency: Graph Traversal}


  \section{Related Work}
    Overview of related work on the topic that's also related to my project
    \subsection{Opinion Mining and Summarization of Discussions}
    \subsection{Multi-document Summarization}
    \subsection{Informal Argumentation}
    \subsection{Stance Classification}
  \section{Motivation}
    Round up why our project is different and interesting
