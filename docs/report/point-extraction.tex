\chapter{Point Extraction\label{chap:point-extraction}}
  \section{Point Concept Overview and Examples}
    A `point' is concept we created to describe a common object in our analysis - originally defined as: a verb and it's context. Points encapsulate both a human-readable extract from the text as well as a pattern representing the core components that can be used to match and compare points to others. Lets take the following sentence from a post in a discussion:

    \smallskip
    \begin{center}
      \blockquote{\textit{I don't think so, an unborn \textbf{child} (however old) \textbf{is} not yet a \textbf{human} being.}}
    \end{center}
    \smallskip

    This sentence puts forward the idea that, until a baby is born, it does not qualify as human. This idea is centered around the verb `\textit{is}', \blockquote{...an unborn child \textbf{is} not yet a human being}. Another sentence in the discussion may also put forward this idea, for example: \blockquote{\textit{So you say: children are not complete humans until birth?}}. Both of these sentences have words that express the same idea only the context differs. We represent points like these using a pattern that Lists the core components, these two sentences both contain points that have this pattern: \texttt{child.subject be.verb human.object}.

    This pattern loses some of the sentence context and is not suitable for use in human-readable text. To overcome this, when extracting points from sentences, points are represented as a pattern but as \textit{a pattern with an accompanying extract}. Extracts are strings made of one or more sentence substrings. The extracts for the points in these two sentences would be:

    \smallskip
    \begin{center}
      \blockquote{\textit{an unborn child is not yet a human being}} \\ \blockquote{\textit{children are not complete humans until birth?}}
    \end{center}
    \smallskip

    Using our representation enables points expressed in different tenses and contexts to be grouped together while still retaining a relevant part of the sentence context to present the human-readable point. Points are the fundamental unit used in our analysis and they exist as part of a larger hierarchical discussion model, see Figure \ref{fig:discmod}. Points are stored in a key value representation with attributes for the pattern, extract, verb and point's original source post in the discussion, see Table \ref{tab:point-keyval}.

    \begin{figure}
      \centering
      \caption{Discussion model showing relationships between subcomponents}

      \TBox[fill=black!5]{10cm}{
        Discussion \\[1ex]
        \TBox[fill=black!10]{9.7cm}{
          Post \\[1ex]
          \TBox[fill=black!15]{9.4cm}{
            Sentence \\[1ex]
            \TBox[fill=green!5]{9.1cm}{
              Point \\[1ex]
              \TBox[fill=green!15]{2.5cm}{
                Pattern \\[1ex]
                \TBox[fill=green!25]{2.2cm}{Component}
              }
              \TBox[fill=green!15]{1.68cm}{Extract}
              \TBox[fill=green!15]{1.68cm}{Verb}
              \TBox[fill=green!15]{1.68cm}{Source}
            }
          }
        }
      }
      \label{fig:discmod}
    \end{figure}

    \begin{table}[]
      \centering
      \caption{The point data structure}
      \label{tab:point-keyval}
      \begin{tabular}{|l|l|}
        \hline
        \textbf{Attribute}       & \textbf{Example Value}                         \\ \hline
        Pattern                  & \texttt{\{woman.nsubj have.verb rights.dobj\}} \\
                                 & Single Component: \texttt{woman.nsubj}         \\ \hline
        Extract                  & ``\textit{A woman has rights.}''               \\ \hline
        Verb                     & to \textit{have}                               \\ \hline
        Source                   & \textit{Post: \#42, Debate: Abortion}          \\ \hline
      \end{tabular}
    \end{table}

    The \textit{Pattern} attribute consists of a list of two or more \textit{Components}. Each component represents a dependency of the verb and the relation of that dependency. For example, if a fetus were to be the subject, then the component would be \texttt{fetus.nsubj} (nominal subject). Relations are defined using Universal Stanford Dependencies\footnote{http://universaldependencies.org/docs/en/dep/}. Patterns are broken down into components to enable certain comparisons between points, for example, to test that \texttt{abortion.nsubj be.verb \textbf{legal.dobj}} and \texttt{abortion.nsubj be.verb \textbf{illegal.dobj}} are counter points.

    With a definition for a point we can now explore the process of extracting these from text. A point, as described above, is built up using information from a dependency parse. A dependency parse is represented in the graph structure showing relationships between different tokens.

	\begin{center}
      \begin{dependency}[edge horizontal padding=0]
          \begin{deptext}
              A \&[2cm] fetus \&[2cm] has \&[2cm] rights \&[0.5cm] . \\
          \end{deptext}
          \depedge{2}{1}{determiner}
          \depedge{3}{2}{nominal subject}
          \depedge{3}{4}{direct object}
          \depedge{3}{5}{punctuation}
          \deproot[edge unit distance=2.1ex]{3}{verb}
      \end{dependency}
	\end{center}
    \vspace{-7mm}

    From this parsed representation of the sentence we can see how both the extract \blockquote{\textit{A fetus has rights.}} and the pattern \texttt{fetus.nsubj have.verb right.dobj} can be extracted. Sentences often contain more than one point, the following dependency parse shows a sentence that references two different points.

    \vspace{3mm}
	\begin{dependency}[edge horizontal padding=0]
		\begin{deptext}
			A \&[0.7cm] baby \&[0.7cm] has \&[0.7cm] rights \& , \& so \& a \&[0.7cm] fetus \& also \&[0.7cm] has \&[0.7cm] rights \\
		\end{deptext}
		\depedge{2}{1}{det}
		\depedge{3}{2}{nsubj}
		\deproot{3}{verb}
		\depedge{3}{4}{dobj}
		\depedge{3}{5}{punct}

		\depedge[edge unit distance=1.2ex,label style={fill=green!15}]{3}{10}{parataxis}

		\depedge{8}{6}{advmod}
		\depedge{8}{7}{det}
		\deproot{10}{verb}
		\depedge{10}{8}{nsubj}
		\depedge{10}{9}{advmod}
		\depedge{10}{11}{dobj}
	\end{dependency}
    \vspace{-2mm}

    Here the parse information helps isolate the two points: \texttt{baby.nsubj have.verb right.dobj} and \texttt{baby.nsubj have.verb right.dobj}. A parataxis relationship connects the two.

  \section{Defining Points with Verb Frames}
  Not all dependencies should be included in the point pattern, only ones essential to the meaning of the point. Some dependencies, like adverbial modifiers and parataxis, that do not introduce information relevant to the point's pattern, can easily be excluded. However, not all dependency types can be classified using a single rule. This is largely due to the different verb classes (transitive, intransitive and ditransitive) and how these are represented by the CoreNLP parser. In order to look for legal patterns in dependency parse graphs we needed an index of verb transitivities that listed allowed patterns for a given verb. We started using FrameNet frames for this task and later extended these with a generic query as a heuristic to match patterns not present in frames.

    \tocless\subsection{VerbNet and FrameNet}
      VerbNet is an XML, verb lexicon that lists classes of verbs and accompanying FrameNet frames \cite{schuler2005verbnet,fillmore2002framenet}. Represented in VerbNet's 274 `classes' are 4402 member verbs. For each of these verbs we can use the frames represented in the source class to determine the allowable forms. An example frame for the verb `murder' is shown in Figure \ref{fig:murder-frame}.

      \begin{figure}
        \centering
        \caption{VerbNet frame example for verb murder}

        \lstset{language=XML}
        \begin{lstlisting}
          <FRAME>
            <DESCRIPTION primary="NP V NP" secondary="Basic Transitive"/>
            <EXAMPLES><EXAMPLE>Brutus murdered Julius Cesar.</EXAMPLE></EXAMPLES>
            <SYNTAX>
              <NP value="Agent"><SYNRESTRS/></NP>
              <VERB/>
              <NP value="Patient"><SYNRESTRS/></NP>
            </SYNTAX>
            <SEMANTICS>...</SEMANTICS>
          </FRAME>
        \end{lstlisting}
        \label{fig:murder-frame}
      \end{figure}

      We use the \texttt{SYNTAX} element information to determine the type of dependencies that can be included in the pattern for a given verb. To create a `verb index' we parsed the VerbNet catalogue into a key-value structure where each verb was the key, and the list of allowed frames the value. Some verbs are listed in more than one class, \textit{feel} for example is listed in seven classes, in these cases the verb was allocated all frames for all classes it was a member of. Using this index, points can be extracted by querying the verb's dependency parse with each of it's frames.

    \tocless\subsection{Matching Frames in Parses}
      With an index of verbs and allowed frames all the information required to identify points in dependency parses is available. However, frames are not inherently capable of querying the dependency graph structure, for this queries for each type of frame must be written. While frames in different categories encode additional semantic information, there are far fewer `syntactically unique' frames than verb classes. Common frames such as \texttt{NounPhrase Verb NounPhrase} cover a large percentage of all listed frames in the index. We have implemented a means of querying dependency parses for 17 of the more common patterns covering 96\% of all frames in the index.

      These queries are written in \textit{Cypher}, the declarative query language implemented by the Neo4j database that we used to store dependency parses during analysis. Figure \ref{fig:npvnpquery} shows an example query. Restrictions imposed commonly require a subject and object, the query result returns the nodes that match these relations. Should a verb \textit{not} have the relations to complete the frame then nothing is returned from the query.

      \begin{figure}
        \centering
        \caption{Example Cypher query for the common \texttt{NP V NP} frame}

        \begin{lstlisting}
          MATCH (verb:Node)
          WHERE verb.uuid = UUID
          MATCH (verb)-[rel_nsubj:REL]->(nsubj:Node)
          MATCH (verb)-[rel_dobj:REL]->(dobj:Node)
          WHERE rel_nsubj.label = "nsubj"
          AND rel_dobj.label = "dobj"
          RETURN nsubj, verb, dobj;
        \end{lstlisting}
        \label{fig:npvnpquery}
      \end{figure}

    \tocless\subsection{The Generic Frame}
      Originally our intent had been to use only queries derived from FrameNet frames to define allowed patterns for points. However there were verbs missing frames for some patterns of interest. Usually this meant a simple frame for the verb was listed but it failed to adequately capture point idea. Take the following example:

      \bigskip
      \begin{center}
        \blockquote{These images reflect the reality of abortions}
      \end{center}

      This is an extract that only matched \texttt{image.nsubj reflect.verb}. Shorter points like this make extracts for points in a cluster considerably more varied, making clusters less cohesive. To overcome this we introduced the idea of the `Generic Frame'. This was a new query that could be run against any dependency graph to extract subjects, objects and open clausal complements. This was used to increase the number of more complete points. For the extract above, the Generic Frame matched this more complete pattern: \texttt{image.nsubj reflect.verb reality.dobj}.

    \tocless\subsection{Copula Verbs}
    The CoreNLP dependency parse differs for copula verbs as the verb is not the root of the parse. Analyzing dependencies \textit{from the verb} only works when the verb is the root. The following examples illustrate the inherently different structure.
      \begin{multicols}{2}
        \raggedcolumns
        \begin{center}
          \begin{dependency}[edge horizontal padding=0]
            \begin{deptext}
              women \&[0.5cm] have \&[0.5cm] rights \\
            \end{deptext}
            \depedge{2}{1}{nsubj}
            \depedge{2}{3}{dobj}
            \deproot[edge unit distance=2.3ex]{2}{root}
          \end{dependency}
        \end{center}
        \columnbreak
        \begin{center}
          \begin{dependency}[edge horizontal padding=0]
            \begin{deptext}
              fetuses \&[0.5cm] are \&[0.5cm] people \\
            \end{deptext}
            \depedge{3}{1}{nsubj}
            \depedge{3}{2}{cop}
            \deproot[edge unit distance=2.3ex]{3}{root}
          \end{dependency}
        \end{center}
      \end{multicols}

      Rather than making the copula verb the head of the sentence we opted to write adjusted queries that could be used for copula verbs when matching against frames. This allows the dependency parse to be left unaltered and makes the implementation more explicit. The example above becomes \texttt{fetus.nsubj be.verb people.dobj} so it matches queries like where people are the `object'.

  \section{Point Extracts}
    So far we have covered the identification of points and how the dependency parse information has been interpreted to arrive at a point's pattern. This is separate from the point extract, this is extracted separately, again using the information in the dependency parse. The task of selecting an extract for a point can be described as follows: recursively select nodes related to the verb until an adequate context for that verb is reached.

    This query was implemented as another Cypher query, similar to verb frames. However, rather than only detecting a small number of expected dependencies, this query follows dependencies recursively. Nodes in the graph that are related to the verb or any of it's descendants are returned as part of the context for the point. To keep points succinct the following relations cannot extend the context tree: \textit{adverbial clause modifiers, clausal subjects, clausal complement, generic dependencies and parataxis}. The following dependency graph represents this recursive process.

    \begin{center}
      \begin{dependency}[edge horizontal padding=0]
        \begin{deptext}
          I \&[0.0cm] do \&[0.0cm] n't \&[0.1cm] think \&[0.5cm] so \&[0.1cm] , \&[0.0cm] an \&[0.0cm] unborn \&[0.1cm] child \&[0.0cm] ( \&[0.0cm] however \&[0.3cm] old \&[0.5cm] ) \&[0.1cm] still \&[0.7cm] has \&[0.2cm] rights \\
        \end{deptext}

        \depedge{4}{1}{nsubj}
        \depedge{4}{2}{aux}
        \depedge{4}{3}{neg}
        \depedge{4}{5}{advmod}
        \depedge{4}{6}{punct}
        \depedge[edge unit distance=1.2ex]{4}{15}{ccomp $\rightarrow$}

        \depedge[edge style={green!75!black, thick}]{9}{7}{det}
        \depedge[edge style={green!75!black, thick}]{9}{8}{amod}
        \depedge[edge style={red!90!black, thick}]{9}{12}{dep $\rightarrow$}

        \depedge{12}{11}{advmod}
        \depedge{12}{10}{punct}
        \depedge{12}{13}{punct}

        \depedge[edge style={green!75!black, thick}]{15}{14}{advmod}
        \depedge[edge style={green!75!black, thick}]{15}{16}{dobj}
        \depedge[edge unit distance=1.9ex,edge style={green!75!black, thick}]{15}{9}{$\leftarrow$ nsubj}

        \deproot[edge unit distance=4.0ex,edge style={green!75!black, thick}]{15}{query root}
      \end{dependency}
    \end{center}

    The green paths represent a query expanding into the graph following permitted dependencies. This gives \blockquote{\textit{an unborn child still has rights}} as the extract for the point. Upon reaching \texttt{dep}, a blacklisted dependency, that route is no longer explored and so excluded from the context. Should the query root have been for the other verb (\textit{think}) the blacklisted clausal compliment would have isolated the extract to \blockquote{\textit{I don't think so,}}.

    This effect is not dissimilar from sentence compression, only there is a starting point `query verb'. The results are not so different from those reported by Knight and Marcu \cite{knight2000statistics}, though the approach was fundamentally different. As they appear to do, we also strip trailing punctuation and capitalize where required. This is done at the summary generation stage in our approach, see Chapter \ref{chap:summary-generation}.

  \section{Extraction Process}
    The previous sections give a theoretical description of our points extraction approach, this final section outlines it's implementation. Making reference to Figure \ref{fig:arch-dia}, the Aggregator submits each post in turn to the Extractor. The Extractor requests dependency parses for the post text from CoreNLP and saves these into the Neo4j graph database. A query is then ran to get all the verbs, for each verb the relevant frames are looked up in the index and run as prepared Cypher queries to extract point patterns. For each matched verb a further query is ran to extract each point's extract. These are returned to the Aggregator as a JSON array and written to disk in preparation for the next module in the pipeline.
