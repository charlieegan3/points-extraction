\chapter{Point Extraction\label{chap:point-extraction}}
  \section{Point Concept Overview and Examples}
    Points are a concept that we created to describe the minimal content unit in our summarization task. We originally defined a point as being a verb and it's required arguments. Points represent a statement made in a discussion in the simplest possible form. Using this representation enables grouping and comparisons, this is used when generating summaries. Take the following two statements as an example:

    \blockquote{\textit{Abortion is always wrong}}, \blockquote{\textit{Abortion is wrong in every way}}

    We wanted to count these as as equivalent and using points as a representation enables this. The core data structure for a point (transferred as a JSON object) is as follows:

    \begin{itemize}
      \item{Verb}
      \item{Source Information (Discussion \& Post Identifier, Stance)}
      \item{\textbf{Components} / Pattern}
      \item{Extract String}
    \end{itemize}

    The \textit{Components} attribute consists of a list of strings - a \textit{Pattern}. Each element represents a dependency of the verb and the relation of that dependency. For example, if \textit{fetus} were to be the subject of the point, then the component would be \texttt{fetus.nsubj}. Relations are defined using universal dependencies\footnote{http://universaldependencies.org/docs/en/dep/}. Using the example from above, the point component representation for both statements would be \texttt{abortion.nsubj be.verb wrong.dobj}. This common pattern makes it possible to reliably group statements that express the same idea - even when the phrasing differs.


  \section{Defining Points with Verb Frames}
    In order to look for legal patterns in dependency parse graphs we needed an index of verb transitivity that listed patterns for a given verb. We started using FrameNet frames for this task and later extended these with a generic query to match patterns not present in frames.
    \subsection{VerbNet and FrameNet}
      VerbNet is a XML, verb lexicon that lists classes of verbs and accompanying FrameNet \cite{fillmore2002framenet} frames \cite{schuler2005verbnet}. Represented in VerbNet's 274 classes are 4402 member verbs. For each of these verbs we can use the frames represented in the source class to determine the allowable forms. An example from for the verb `Murder' is given below.

      \lstset{language=XML}
      \begin{lstlisting}
          <FRAME>
              <DESCRIPTION primary="NP V NP" secondary="Basic Transitive"/>
              <EXAMPLES><EXAMPLE>Brutus murdered Julius Cesar.</EXAMPLE></EXAMPLES>
              <SYNTAX>
                  <NP value="Agent"><SYNRESTRS/></NP>
                  <VERB/>
                  <NP value="Patient"><SYNRESTRS/></NP>
              </SYNTAX>
              <SEMANTICS>...</SEMANTICS>
          </FRAME>
      \end{lstlisting}

      We experimented using the information in the \texttt{primary} attribute. This information is did not always match what was annotated in the \texttt{SYNTAX} attribute. We switched to using the \texttt{SYNTAX} attribute content instead. To create the verb index described above we parsed the VerbNet catalogue into a key value structure. Each verb was a key, and list of allowed frames the value. Some verbs are listed in more than one class, \textit{feel} for example is listed in seven classes, in these cases the verb was allocated all frames for all it's classes.

      Using this index, points can be extracted by querying the verb's dependency parse with each of it's frames.

    \subsection{The Generic Frame}
      Originally our intent had been to use only FrameNet frames to define allowed patterns for points. However there were verbs that were missing frames for \textit{all} possible patterns of interest. Usually this meant that there was a simple frame for the verb but it failed to adequately capture the context. Take the following example:

      \blockquote{These images reflect the reality of abortions}

      This is an extract that matched \texttt{image.nsubj reflect.verb}. Having these shorter points makes groups of extracts more variable which in turn means that our grouping function is not as useful. To overcome this we introduced the idea of the generic frame. This was a new query that could be run against a dependency graph that looked for subjects, objects and open clausal complements. This was used to increase the number of more complete points. For the extract above, the generic frame matched this more complete pattern: \texttt{image.nsubj reflect.verb reality.dobj}.

    \subsection{Copula Verbs}
      Copula verbs are not the head of the sentence in output from the CoreNLP dependency parser. Take the following example:
      \begin{multicols}{2}
        \raggedcolumns
        \begin{itemize}[label={}]
          \item{\blockquote{A woman has rights.}}
          \item{\texttt{det(woman, a)}}
          \item{\texttt{nsubj(has, woman)}}
          \item{\texttt{dobj(has, rights)}}
        \end{itemize}
        \columnbreak
        \begin{itemize}[label={}]
          \item{\blockquote{A fetus is a person.}}
          \item{\texttt{det(fetus, a)}}
          \item{\texttt{nsubj(person, fetus)}}
          \item{\texttt{cop(person, is)}}
          \item{\texttt{det(person, a)}}
        \end{itemize}
      \end{multicols}

      Rather than making the copula verb the head of the sentence we opted to write adjusted queries that could be used for copula verbs when matching against frames. This allows the dependency parse to be left unaltered and makes the implementation more explicit. The result is still much the same, the example above becomes \texttt{fetus.nsubj be.verb person.dobj} so it still matches ``points where people are the object''.

  \section{Minimum Requirements}
    \section{Generic Match Requirements}
  \section{Point Extracts}
  \section{Extraction Process}
