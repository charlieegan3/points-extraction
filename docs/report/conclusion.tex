\chapter{Summary \& Conclusion \label{chap:conclusion}}
  \section{Summary}
    In this project we have implemented a robust method for extracting points, a meaningfully shorter content unit. We make use of these in a summarization task by clustering points into cohesive sections. We then evaluate the effectiveness of our approach by comparing our summaries against summaries generated by a baseline statistical tool.

    We were able to meet most of the projects initial goals. Using the dependency parse we have implemented a means of extracting more useful and complete point extracts. We also improved on the detection of counter points by expanding the approach to account for antonyms. While we also implemented an approach for the identification of co-occurring points the results seem to be more variable and are dependent on large discussions where participants make many points. We did not do more than investigate stance classification, our corpus has stance annotations however we never included this information in summaries as we wanted to make sure the approach was easy to generalize.

    We opted to present the results of the analysis as summaries of the debate. Here we were able to go beyond our goals of counter/co-occurring points and include additional sections based on the points we had extracted.

    There are however areas that require further work. Results from our evaluation suggest that certain presentation decisions we not universally popular. We also found that our means of selecting extracts from clusters was not significantly better than random, this appeared to be largely because points with poor readability scored well on the bigram model. \textcolor{red}{We were able to reject 1 (or 2/3) of our 4 hypotheses}. The evaluation did also present positive results, giving justification for further work in the area.

  \section{Further Work}
  \section{Conclusion}
