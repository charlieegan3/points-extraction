\chapter{Introduction\label{chap:introduction}}
  More people are online than ever before. Comment threads and discussion forums allow us to spend spare time participating as contributors - rather than just consuming content. From the latest blockbuster title to yesterday's celebrity misdemeanor, there's an online conversation already well underway. These discussions, where statements are encoded in natural language, represent a large untapped resource of ideas. A higher-level view of a discussion would be useful and interesting to many. Online retailers might analyze product reviews; social scientists could gain valuable insight on social media debate; and marketers could better understand the discussions of their customers.

  This project explores an approach for summarizing such discussions. At the core of the approach is the notion of a `point' - a short refined statement, extracted as a verb and its syntactic arguments. We model a user's contribution to a discussion as a series of arguments, where an argument is a point made in their post relevant to a topic. These points are clustered and analyzed to give a summary of common arguments made in the discussion. To test our approach, we ran an evaluation using summaries generated from online political discussions \cite{walker2012corpus}.

  \section{Motivation}
    Text summarization is a well established task in the field of Natural Language Processing. Summarization sub-tasks such as sentence extraction and compression, where text is selected and removed to arrive at a summary, have become commonplace due to the complexities introduced by abstractive methods. Extractive methods have become largely statistical using Naive-Bayes \cite{kupiec1995trainable} approaches and, more recently even Neural Networks \cite{svore2007enhancing}.

    Argumentation mining, a newer area of study, has the aim of identifying argumentative discourse structure in text. Argumentation mining has been used in the processing of formal documents (where arguments are often stated more explicitly) such as parliamentary records \cite{palau2009argumentation} and legal documents \cite{montemagni2010semantic}. However, argumentation mining has also more recently been applied to more informal texts \cite{park2015conditional}. Applications of argument mining on informal texts, coupled with summarization, encapsulates much of the novelty for this project.

    Using `points' as a data structure was adopted from a previous project in the department that used a similar concept in a system with a focus on stance classification. While this implemented point identification, it was limited by its point definition: a verb, subject and object. This lead to disfluencies caused by the absence of important syntactic arguments to the verb. While the tool was capable of linking contrasting points, this was based only on the presence of negation terminology.

    Our project was based on this broad concept of a point, as well as the idea that they could be used to build a high-level summary of a discussion when considered to represent basic units of informal argumentation. Argumentation mining, as referenced as part of this project, focuses on the how points, referencing topics, can be compared at the level of the whole discussion --- rather than the intricacies of the arguments of individual posts. News article comment sections; forum threads; film \& product reviews and even extended email conversations are all candidate applications for such analysis. However, the focus of this work is on political discussions.

  \section{Objectives}
    The overall objective for the project was to implement a means of summarizing large discussions; in particular, discussions that take place on social media with many participants. We wanted to find a means of representing the key concepts under discussion. Which ideas were related? Or contradictory? For this task, we chose to use points; and the relationships between them; to form a condensed representation of the discussion.

    Continuing the work of a previous project that used a naive implementation of a point (subject, verb, object), we wanted to build on this and improve on the extraction of points from text. Fundamentally, this meant extracting more of the verb's arguments and related tokens - rather than only the subject and object. Take the following sentence:

    \medskip
    \begin{center}
    \blockquote{\textit{I don't think so, an unborn child (however old) is not yet a human being.}}
    \end{center}
    \medskip

    From this, uses the subject and object syntactic arguments of \textit{is}, gives: \texttt{child.subject be.verb human.object}. This is useful, a structure like this can be linked with a point extracted from another sentence like: \blockquote{\textit{So you say: children are not complete humans until birth?}} (child is the lemma of children). However, this lossy abstraction is not suited to presentation. Our objective, with regards to better extracting points, was to \textit{additionally} extract the sub-sentence context in which a point was made. Continuing this example, the following string would be a `good' extract:

    \medskip
    \begin{center}
    \blockquote{\textit{an unborn child is not yet a human being}}
    \end{center}
    \medskip

    This is almost half the length of the original sentence, but still represents the core idea expressed around being human --- and is still easily readable. As part of generating summaries we wanted to go beyond just extracting points and investigate relationships between them. Counter points pairs --- points that represent opposing ideas --- and co-occurring points --- points commonly raised together by multiple users --- were of particular interest for use as summary content.

    \medskip

    The project's success is evaluated with respect to these objectives.
